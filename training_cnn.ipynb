{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4AXDtBU72u2"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "laAYPdu_7wVK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from functions.data_processing import create_set_cnn\n",
    "from functions.prediction import make_predictions, generate_pdda_preds\n",
    "from functions.visualization import posHeatmapXY, spatial_plot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTVjqEc68NJz"
   },
   "source": [
    "# Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is hosted publicly at https://doi.org/10.5281/zenodo.6303665."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hG18CQ9QdekC"
   },
   "outputs": [],
   "source": [
    "datadir = 'Dataset' # path to data folder\n",
    "modeldir = 'models' # path to model folder (optional, if you want to save models' weights)\n",
    "preds_dir = 'preds' # path to model folder (optional, if you want to save models' predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define basic values\n",
    "rooms = ['testbench_01', 'testbench_01_furniture_low', 'testbench_01_furniture_mid', 'testbench_01_furniture_high']\n",
    "concrete_rooms = ['testbench_01_furniture_low_concrete', 'testbench_01_furniture_mid_concrete', 'testbench_01_furniture_high_concrete']\n",
    "other_scenarios = ['testbench_01_rotated_anchors']\n",
    "anchors = ['anchor1', 'anchor2', 'anchor3', 'anchor4']\n",
    "channels = ['37','38','39']\n",
    "polarities = ['V','H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nini\\\\Desktop\\\\Libra\\\\sensors-positioning'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pM2Uh7didey2"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tag_filename, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m     12\u001b[0m     tag_dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fp))\n\u001b[1;32m---> 14\u001b[0m tag_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m tag_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroom\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(room)\n\u001b[0;32m     16\u001b[0m tag_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(channel)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:455\u001b[0m, in \u001b[0;36m_json_normalize\u001b[1;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# check to see if a simple recursive function is possible to\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# improve performance (see #15621) but only for cases such\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# as pd.Dataframe(data) or pd.Dataframe(data, sep)\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    449\u001b[0m     record_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m max_level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    454\u001b[0m ):\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[43m_simple_json_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m y\u001b[38;5;241m.\u001b[39mvalues()] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m data):\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;66;03m# naive normalization, this is idempotent for flat records\u001b[39;00m\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;66;03m# and potentially will inflate the data considerably for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# TODO: handle record value which are lists, at least error\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m#       reasonably\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:236\u001b[0m, in \u001b[0;36m_simple_json_normalize\u001b[1;34m(ds, sep)\u001b[0m\n\u001b[0;32m    234\u001b[0m     normalised_json_object \u001b[38;5;241m=\u001b[39m _normalise_json_ordered(data\u001b[38;5;241m=\u001b[39mds, separator\u001b[38;5;241m=\u001b[39msep)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ds, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 236\u001b[0m     normalised_json_list \u001b[38;5;241m=\u001b[39m [_simple_json_normalize(row, sep\u001b[38;5;241m=\u001b[39msep) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m ds]\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalised_json_list\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m normalised_json_object\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:236\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    234\u001b[0m     normalised_json_object \u001b[38;5;241m=\u001b[39m _normalise_json_ordered(data\u001b[38;5;241m=\u001b[39mds, separator\u001b[38;5;241m=\u001b[39msep)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ds, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m--> 236\u001b[0m     normalised_json_list \u001b[38;5;241m=\u001b[39m [\u001b[43m_simple_json_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m ds]\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalised_json_list\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m normalised_json_object\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:234\u001b[0m, in \u001b[0;36m_simple_json_normalize\u001b[1;34m(ds, sep)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# expect a dictionary, as most jsons are. However, lists are perfectly valid\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ds, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 234\u001b[0m     normalised_json_object \u001b[38;5;241m=\u001b[39m \u001b[43m_normalise_json_ordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ds, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    236\u001b[0m     normalised_json_list \u001b[38;5;241m=\u001b[39m [_simple_json_normalize(row, sep\u001b[38;5;241m=\u001b[39msep) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m ds]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:178\u001b[0m, in \u001b[0;36m_normalise_json_ordered\u001b[1;34m(data, separator)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_normalise_json_ordered\u001b[39m(data: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], separator: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    Order the top level keys and then recursively go to depth\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    dict or list of dicts, matching `normalised_json_object`\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     top_dict_ \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m)}\n\u001b[0;32m    179\u001b[0m     nested_dict_ \u001b[38;5;241m=\u001b[39m _normalise_json(\n\u001b[0;32m    180\u001b[0m         data\u001b[38;5;241m=\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m)},\n\u001b[0;32m    181\u001b[0m         key_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    182\u001b[0m         normalized_dict\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    183\u001b[0m         separator\u001b[38;5;241m=\u001b[39mseparator,\n\u001b[0;32m    184\u001b[0m     )\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtop_dict_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnested_dict_}\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:178\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_normalise_json_ordered\u001b[39m(data: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], separator: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    Order the top level keys and then recursively go to depth\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    dict or list of dicts, matching `normalised_json_object`\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     top_dict_ \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m)}\n\u001b[0;32m    179\u001b[0m     nested_dict_ \u001b[38;5;241m=\u001b[39m _normalise_json(\n\u001b[0;32m    180\u001b[0m         data\u001b[38;5;241m=\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m)},\n\u001b[0;32m    181\u001b[0m         key_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    182\u001b[0m         normalized_dict\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    183\u001b[0m         separator\u001b[38;5;241m=\u001b[39mseparator,\n\u001b[0;32m    184\u001b[0m     )\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtop_dict_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnested_dict_}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#read data\n",
    "data = defaultdict(lambda: defaultdict(lambda: defaultdict (lambda: defaultdict(list))))\n",
    "\n",
    "anchor_data = defaultdict(lambda: defaultdict(lambda: defaultdict (lambda: defaultdict(list))))\n",
    "final_df = pd.DataFrame()\n",
    "for room in rooms + concrete_rooms + other_scenarios: \n",
    "    for channel in channels:  \n",
    "        for polarity in polarities: \n",
    "             \n",
    "            tag_filename = f'{datadir}/{room}/tag_ml_export_CH{channel}_{polarity}.json'\n",
    "            with open(tag_filename, encoding='utf-8-sig') as fp:\n",
    "                tag_dataset = json.loads(''.join(line.strip() for line in fp))\n",
    "\n",
    "            tag_df = pd.json_normalize(tag_dataset)\n",
    "            tag_df['room'] = str(room)\n",
    "            tag_df['channel'] = str(channel)\n",
    "            tag_df['polarity'] = str(polarity)\n",
    "            # tag_df = pd.read_json(tag_filename, orient='records')\n",
    "            \n",
    "            anchor_filename = f'{datadir}/{room}/anchor_ml_export_CH{channel}_{polarity}.json'\n",
    "            \n",
    "            with open(anchor_filename, encoding='utf-8-sig') as fp:\n",
    "                anchor_dataset = json.loads(''.join(line.strip() for line in fp))\n",
    "\n",
    "            anchor_df = pd.json_normalize(anchor_dataset)\n",
    "            \n",
    "            # anchor_df = pd.read_json(anchor_filename, orient='records')\n",
    "\n",
    "            df = tag_df.merge(anchor_df)\n",
    "            # remove calibration points\n",
    "            df.drop(df[(df['x_tag']==0).values | (df['y_tag']==0).values | (df['z_tag']==0).values].index, inplace=True)\n",
    "            for anchor in anchors:\n",
    "                data[room][anchor][channel][polarity] = df[df['anchor']==int(anchor[-1])]\n",
    "                anchor_data[room][anchor][channel][polarity] = anchor_df\n",
    "            final_df = pd.concat([final_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = [ 'point','room','anchor','channel', 'polarity', 'reference_power','pdda_input_real','pdda_input_imag', 'relative_power', 'true_phi', 'true_theta','x_tag', 'y_tag', 'z_tag'] \n",
    "new_order += list((set(cols) - set(new_order)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[new_order]\n",
    "final_df = final_df.sort_values(['point', 'room', 'anchor', 'channel', 'polarity'])\n",
    "final_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_pickle('libra_dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPOYW7bmi6e-"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected number of training and validation points is small so the point selection is done in an orderly fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OctEd1kHhcFx"
   },
   "outputs": [],
   "source": [
    "#split points into train/test/val points\n",
    "points = data['testbench_01']['anchor1']['37']['H'].iloc[:, 1:7]\n",
    "\n",
    "# only point locations that appear in all simulated environments are used.\n",
    "# some point locations that fall ontop of furniture are thus thrown away.\n",
    "for room in rooms + concrete_rooms:\n",
    "    for anchor in anchors:\n",
    "        for channel in channels:\n",
    "            for polarization in ['H','V']:\n",
    "                points = pd.merge(points, data[room][anchor][channel][polarization]['point'], on='point')\n",
    "\n",
    "# grid of training points\n",
    "xs = sorted(np.unique(points['x_tag']))[::18]\n",
    "ys = sorted(np.unique(points['y_tag']))[::9]\n",
    "train_points = points[points['x_tag'].isin(xs) & points['y_tag'].isin(ys)]\n",
    "\n",
    "# grid of validation points\n",
    "xs = sorted(np.unique(points['x_tag']))[3::10]\n",
    "ys = sorted(np.unique(points['y_tag']))[3::10]\n",
    "val_points = points[points['x_tag'].isin(xs) & points['y_tag'].isin(ys)]\n",
    "\n",
    "test_points = points.drop(index=train_points.index).drop(index=val_points.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GVhYwlXKwBER"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size:\t14\n",
      "Validation Set Size:\t27\n",
      "Testing Set Size:\t2353\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Set Size:\\t{len(train_points)}')\n",
    "print(f'Validation Set Size:\\t{len(val_points)}')\n",
    "print(f'Testing Set Size:\\t{len(test_points)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CXmD-QbIhedi"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_points.iloc[:,1:2].values,train_points.iloc[:,2:3].values)\n",
    "plt.scatter(val_points.iloc[:,1:2].values,val_points.iloc[:,2:3].values)\n",
    "plt.legend(['Training Points', 'Validation Points'], framealpha=0.94, fancybox=True)\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(range(-2,15,2))\n",
    "ax.set_yticklabels(range(-1,7,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset based on the picked training, validation and testing points. Additionally, the create_set function processes the IQ and RSSI data by applying IQ phase shifting and RSSI normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is augmented by reducing amplitude of IQ values and RSSI for randomly picked anchors. Finally, the IQ-images are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Vdyqp2I8tBLb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n",
      "['reference_power', 'pdda_input_real_1', 'pdda_input_real_2', 'pdda_input_imag_2', 'pdda_input_real_3', 'pdda_input_imag_3', 'pdda_input_real_4', 'pdda_input_imag_4', 'pdda_input_real_5', 'pdda_input_imag_5']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'power'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'power'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#creat train/test/val sets for cnn\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_set_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrooms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m x_val, y_val \u001b[38;5;241m=\u001b[39m create_set_cnn(data, rooms \u001b[38;5;241m+\u001b[39m concrete_rooms \u001b[38;5;241m+\u001b[39m other_scenarios, val_points)                         \n\u001b[0;32m      4\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m create_set_cnn(data, rooms \u001b[38;5;241m+\u001b[39m concrete_rooms \u001b[38;5;241m+\u001b[39m other_scenarios, test_points)\n",
      "File \u001b[1;32m~\\Desktop\\Libra\\sensors-positioning\\functions\\data_processing.py:125\u001b[0m, in \u001b[0;36mcreate_set_cnn\u001b[1;34m(data, rooms, points, augmentation)\u001b[0m\n\u001b[0;32m    121\u001b[0m         x[room][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miq_image\u001b[39m\u001b[38;5;124m'\u001b[39m], x[room][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m create_iq_images(tmp[room])\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augmentation:\n\u001b[1;32m--> 125\u001b[0m     x_reduced \u001b[38;5;241m=\u001b[39m [reduceAmplitude(tmp, rooms, scale_util\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m)]\n\u001b[0;32m    126\u001b[0m     x_aug, y_aug \u001b[38;5;241m=\u001b[39m tmp, copy\u001b[38;5;241m.\u001b[39mdeepcopy(y)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m room \u001b[38;5;129;01min\u001b[39;00m rooms:\n",
      "File \u001b[1;32m~\\Desktop\\Libra\\sensors-positioning\\functions\\data_processing.py:125\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    121\u001b[0m         x[room][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miq_image\u001b[39m\u001b[38;5;124m'\u001b[39m], x[room][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m create_iq_images(tmp[room])\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augmentation:\n\u001b[1;32m--> 125\u001b[0m     x_reduced \u001b[38;5;241m=\u001b[39m [\u001b[43mreduceAmplitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrooms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_util\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m)]\n\u001b[0;32m    126\u001b[0m     x_aug, y_aug \u001b[38;5;241m=\u001b[39m tmp, copy\u001b[38;5;241m.\u001b[39mdeepcopy(y)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m room \u001b[38;5;129;01min\u001b[39;00m rooms:\n",
      "File \u001b[1;32m~\\Desktop\\Libra\\sensors-positioning\\functions\\data_processing.py:177\u001b[0m, in \u001b[0;36mreduceAmplitude\u001b[1;34m(df, rooms, scale_util, mode)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamplitude\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    176\u001b[0m     out[room][anchor][channel][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdda_input_real_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[index] \u001b[38;5;241m=\u001b[39m util[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdda_input_real_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m scale\n\u001b[1;32m--> 177\u001b[0m     out[room][anchor][channel][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpower\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[index] \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpower\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m    180\u001b[0m         polar[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamplitude_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(util[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdda_input_real_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mutil[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdda_input_imag_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m scale\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\libra\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'power'"
     ]
    }
   ],
   "source": [
    "#creat train/test/val sets for cnn\n",
    "x_train, y_train = create_set_cnn(data, rooms, train_points, augmentation=True)\n",
    "x_val, y_val = create_set_cnn(data, rooms + concrete_rooms + other_scenarios, val_points)                         \n",
    "x_test, y_test = create_set_cnn(data, rooms + concrete_rooms + other_scenarios, test_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wy1MUv38cYw"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.models import cnnArch\n",
    "model_arch = cnnArch\n",
    "model_arch_name = 'cnn_arch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSw4n9rPE4OP"
   },
   "outputs": [],
   "source": [
    "#training parameters\n",
    "fit_params = {'batch_size': 128, 'validation_batch_size':32, 'epochs': 1500, 'verbose': 1, \n",
    "              'callbacks': [keras.callbacks.EarlyStopping(monitor='val_mae', mode='min', verbose=0, patience=75, restore_best_weights=True)]}\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7uvysvOejVN"
   },
   "outputs": [],
   "source": [
    "load = False # load an already saved model\n",
    "\n",
    "if load:\n",
    "    models_dict = {}\n",
    "    for room in rooms:\n",
    "        models_dict[room] = keras.models.load_model(f'{modeldir}/{model_arch_name}/{room}')\n",
    "\n",
    "else:\n",
    "\n",
    "    models_dict = defaultdict(lambda: model_arch(learning_rate).model)\n",
    "\n",
    "    for training_room in rooms:\n",
    "\n",
    "        print(training_room)\n",
    "        models_dict[training_room] = model_arch(learning_rate).model\n",
    "\n",
    "        ytrain = pd.concat([y_train[training_room][anchor]['37'] for anchor in anchors], axis=1)\n",
    "        yval = pd.concat([y_val[training_room][anchor]['37'] for anchor in anchors], axis=1)\n",
    "\n",
    "        models_dict[training_room].fit(x_train[training_room], ytrain,\n",
    "                                    validation_data=(x_val[training_room], yval), \n",
    "                                    **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiuSUMZtIjGz"
   },
   "outputs": [],
   "source": [
    "save =  False # save the model\n",
    "\n",
    "if save:\n",
    "    for room in rooms:\n",
    "        models_dict[room].save(f'{modeldir}/{model_arch_name}/{room}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZfsfeDdqd2P"
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZxMe22Fwt-k"
   },
   "outputs": [],
   "source": [
    "# generate AoA and position predictions as well as mean euclidean distance error \n",
    "# and AoA mean absolute error for all training and testing room combinations\n",
    "preds, true_pos = make_predictions(x_test, y_test, models_dict, training_rooms=rooms, \n",
    "                                        testing_rooms=rooms + concrete_rooms + other_scenarios,\n",
    "                                        test_points=test_points, anchor_data=anchor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_to_regular(d):\n",
    "    if isinstance(d, (defaultdict, dict)):\n",
    "        d = {k: default_to_regular(v) for k, v in d.items()}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtfSfsYs_-pw"
   },
   "outputs": [],
   "source": [
    "# save the predictions dictionary\n",
    "save_preds = False\n",
    "if save_preds:\n",
    "    results_path = f'{preds_dir}/preds_{model_arch_name}.npy'\n",
    "    np.save(results_path, default_to_regular(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnVo0ChQjfRd"
   },
   "outputs": [],
   "source": [
    "# load the predictions dictionary\n",
    "load_preds = False\n",
    "if load_preds:\n",
    "    preds = np.load(f'{preds_dir}/preds_{model_arch_name}.npy', allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce pdda predictions\n",
    "pdda_res = generate_pdda_preds(data, rooms + concrete_rooms + other_scenarios, test_points, anchor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WDyvvHyoyyt"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce pos maes heatmap\n",
    "posHeatmapXY(preds['pos_maes'][:,:7], pdda_res['pos_maes'][:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce error per point plot\n",
    "spatial_plot(preds['pos_preds']['testbench_01_furniture_low']['testbench_01_furniture_high'], true_pos, testing_room = 'testbench_01_furniture_high', mode = 'xy',vmax = 3, cmap = 'PuBu')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bPOYW7bmi6e-"
   ],
   "name": "Triplets of Anchors Model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
